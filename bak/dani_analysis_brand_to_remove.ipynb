{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fd7eb8b5-1e17-4b67-92cb-c4d4bec97dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages for model learning\n",
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "import pandas as pd\n",
    "import sklearn.model_selection\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import gpytorch\n",
    "import botorch\n",
    "\n",
    "# Packages for data loading\n",
    "import json\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3bb42c13-8a0a-43d2-be92-1243fa82c2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages for Jupyter notebook\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "import base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e99da150",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import cache\n",
    "\n",
    "tensor_to_image = torchvision.transforms.ToPILImage()\n",
    "@cache\n",
    "def tensor_to_url(tensor, size=128):\n",
    "    return fr\"data:image/png;base64,{base64.b64encode(PIL.ImageOps.contain(tensor_to_image(tensor), (size, size))._repr_png_()).decode('ascii')}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33eb9613-1cb7-4a50-be91-96f1c970e580",
   "metadata": {},
   "source": [
    "# Load and process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "40d03fde-9bb9-454c-845d-ba6a20b5ea43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make all photos square\n",
    "def pad_image(img):\n",
    "    h,w = img.shape[1:]\n",
    "    if h != w:\n",
    "        new_w = max(h,w)\n",
    "        pad_h, rem_h = divmod(new_w - h, 2)\n",
    "        pad_w, rem_w = divmod(new_w - w, 2)\n",
    "        padding = [pad_w, pad_h, pad_w+rem_w, pad_h+rem_h]\n",
    "        return torchvision.transforms.functional.pad(img, padding, padding_mode='edge')\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cfb725f3-a290-4201-9064-ebc7ada35dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F://datasets//fashion_designers_list//\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "400\n",
      "450\n",
      "500\n",
      "550\n",
      "600\n",
      "650\n",
      "700\n",
      "750\n",
      "800\n",
      "850\n",
      "900\n",
      "950\n",
      "1000\n",
      "1050\n",
      "1100\n",
      "1150\n",
      "1200\n",
      "1250\n",
      "1300\n",
      "1350\n",
      "1400\n",
      "1450\n",
      "1500\n",
      "1550\n",
      "1600\n",
      "1650\n",
      "1700\n",
      "1750\n",
      "1800\n",
      "1850\n",
      "1900\n",
      "1950\n",
      "2000\n",
      "2050\n",
      "2100\n",
      "2150\n",
      "2200\n",
      "2250\n",
      "2300\n",
      "2350\n",
      "2400\n",
      "2450\n",
      "2500\n",
      "2550\n",
      "2600\n",
      "2650\n",
      "2700\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "\n",
    "# img_root = './dataset/dress_pure_renamed/'\n",
    "# train_metadata = json.loads(Path('./dataset/dress_pure_renamed/train.json').read_text())\n",
    "# test_metadata = json.loads(Path('./dataset/dress_pure_renamed/test.json').read_text())\n",
    "# val_metadata = json.loads(Path('./dataset/dress_pure_renamed/val.json').read_text())\n",
    "\n",
    "# class_labels = ['christian_dior', 'maison_margiela']\n",
    "torch.manual_seed(0)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = \"cpu\"\n",
    "\n",
    "# img_root = Path('./dataset/')\n",
    "# train_metadata = json.loads((img_root / 'train.json').read_text())\n",
    "# test_metadata = json.loads((img_root / 'test.json').read_text())\n",
    "# val_metadata = json.loads((img_root / 'val.json').read_text())\n",
    "# img_root = \"F://datasets//fashion_brands//\"\n",
    "img_root = \"F://datasets//fashion_designers_list//\"\n",
    "\n",
    "print(img_root)\n",
    "\n",
    "train_metadata = json.loads(Path(img_root + '\\/train.json').read_text())\n",
    "test_metadata = json.loads(Path(img_root + '\\/test.json').read_text())\n",
    "val_metadata = json.loads(Path(img_root + '\\/val.json').read_text())\n",
    "\n",
    "# class_labels = [\"alexander_mcqueen\",\"donatella_versace\",\"karl_lagerfeld\",\"yves_saint_laurent\"]\n",
    "class_labels = [\"alexander_mcqueen\", \"donatella_versace\", \"john_galliano\", \"karl_lagerfeld\", \"yves_saint_laurent\"]\n",
    "class_labels = [x.replace('_',' ') for x in class_labels]\n",
    "class_num = 5\n",
    "image_size = 224\n",
    "\n",
    "n_train = len(train_metadata)\n",
    "n_test = len(test_metadata)\n",
    "n_val = len(val_metadata)\n",
    "n_all = n_train + n_test + n_val\n",
    "\n",
    "all_classes = torch.empty(n_all, dtype=torch.int)\n",
    "all_images = [None]*n_all\n",
    "for i,meta in enumerate((*train_metadata, *test_metadata, *val_metadata)):\n",
    "    if i%50==0:\n",
    "        print(i)\n",
    "    all_classes[i] = meta['label']\n",
    "    all_images[i] = torchvision.io.read_image(str(Path(img_root + meta['file_path'])),mode=torchvision.io.ImageReadMode.RGB).to(device)\n",
    "#     all_images[i] = pad_image(torchvision.transforms.functional.resize(all_images[i], image_size, antialias=True)) Dani\n",
    "    all_images[i] = torchvision.transforms.functional.resize(pad_image(all_images[i]), image_size, antialias=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a0237e2a-2f03-4456-8bf8-9e90ff44cb73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5, dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "n_classes = all_classes.max() + 1\n",
    "print(n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "26bd2456-e055-419b-9f70-c1bc8bdda531",
   "metadata": {},
   "outputs": [],
   "source": [
    "from resnet_model import resnet_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9877fb85-1a67-4df9-923d-803474b4dc7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Users\\nora\\anaconda3\\envs\\deep_gp\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "E:\\Users\\nora\\anaconda3\\envs\\deep_gp\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet_extractor = resnet_model(class_num,backbone=\"resnet18\").to(device)\n",
    "# checkpoint = torch.load('results//fashion_brands.3layer.bsz_128sz_224.sgd0.002//best_model.pt', map_location=device)\n",
    "checkpoint = torch.load('results//fashion_designers_c5.3layer.bsz_128sz_224.sgd0.002//best_model.pt', map_location=device)\n",
    "resnet_extractor.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "45ad8abd-931f-4074-927e-a3d2c983cf42",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in resnet_extractor.parameters():\n",
    "    p.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bd22b10c-6ce4-497e-a3ea-d7314c643c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Users\\nora\\anaconda3\\envs\\deep_gp\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define resnet feature extractor\n",
    "resnet_input_transform = torchvision.models.ResNet18_Weights.DEFAULT.transforms().to(device)\n",
    "crop_size = resnet_input_transform.crop_size[0]\n",
    "print(crop_size)\n",
    "\n",
    "all_data = torch.empty(n_all, 3, crop_size, crop_size).to(device)\n",
    "for i in range(n_all):\n",
    "    # print(\"i=\"+str(i))\n",
    "    # print(all_images[i].shape)\n",
    "    all_data[i] = resnet_input_transform(all_images[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f81251be-514f-4ed3-a3c7-b68abd971300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "left = n_all%batch_size\n",
    "batches_num = int(n_all/batch_size)\n",
    "print(left)\n",
    "if left!= 0:\n",
    "    batches_num += 1\n",
    "all_embeddings = []\n",
    "# print(batches_num)\n",
    "for i in range(1,batches_num+1):\n",
    "    # print(i)\n",
    "    if i == batches_num:\n",
    "        all_embeddings.append(resnet_extractor.backbone(all_data[(batches_num-1)*batch_size:]))\n",
    "    else:\n",
    "        all_embeddings.append(resnet_extractor.backbone(all_data[(i-1)*batch_size:i*batch_size]))\n",
    "    # print(len(all_embeddings))\n",
    "all_embeddings = torch.cat(all_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bdcff0f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2702, 512])\n",
      "2702\n",
      "2702\n"
     ]
    }
   ],
   "source": [
    "print(all_embeddings.shape)\n",
    "print(n_all)\n",
    "print(len(all_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tesing the renset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "541\n",
      "541\n",
      "[3 0 2 4 1 4 3 0 2 4 4 2 3 4 4 2 0 1 1 3 1 4 1 4 2 1 2 4 2 4 2 4 3 2 4 2 2\n",
      " 4 4 4 4 3 1 0 1 3 4 4 1 1 1 2 0 0 1 2 4 1 2 4 3 4 3 2 1 3 2 3 2 2 2 2 2 4\n",
      " 4 2 0 4 3 2 4 4 1 4 4 2 4 1 0 0 2 0 4 2 0 4 2 1 4 0 0 4 0 2 2 1 3 2 4 2 1\n",
      " 0 4 4 4 2 4 2 4 2 4 4 4 4 0 4 4 4 3 4 1 0 0 2 2 3 4 2 2 4 0 4 4 2 0 2 2 2\n",
      " 2 4 4 2 4 4 2 4 0 3 2 0 1 4 4 2 0 2 2 1 4 2 4 2 4 0 4 3 3 2 2 0 4 3 4 2 2\n",
      " 4 2 4 3 1 1 0 2 4 0 4 4 4 0 4 4 2 2 0 4 4 1 1 4 0 4 3 0 4 4 4 2 4 4 4 0 4\n",
      " 4 0 2 4 2 2 2 2 3 4 2 4 0 0 0 3 0 2 2 2 2 3 2 3 3 2 4 4 4 2 1 4 4 4 4 4 0\n",
      " 2 4 2 4 1 4 4 3 2 1 4 3 3 4 1 2 4 4 4 1 2 4 0 4 3 4 4 1 4 4 4 4 1 4 3 2 0\n",
      " 4 4 4 2 0 4 1 4 1 4 0 2 0 2 2 4 1 4 2 4 0 4 3 0 4 0 3 2 4 0 2 0 2 2 2 4 0\n",
      " 3 2 4 4 3 0 1 4 4 4 1 4 2 0 3 2 4 1 1 4 2 2 0 2 4 0 3 0 3 0 1 4 4 4 2 0 4\n",
      " 2 4 4 3 2 2 3 0 4 0 3 0 2 4 4 4 2 0 4 4 4 4 4 3 4 4 2 4 4 2 2 1 4 1 0 4 2\n",
      " 0 2 4 2 2 4 3 3 3 4 2 4 0 2 4 4 4 4 4 4 4 2 4 4 4 4 2 2 3 2 1 1 4 4 2 1 4\n",
      " 4 4 2 3 3 3 0 2 4 4 1 4 3 1 0 2 2 4 1 4 4 4 3 4 4 4 2 4 4 0 1 2 2 2 0 3 0\n",
      " 4 1 4 2 4 0 4 0 1 1 0 4 4 2 2 4 2 2 4 2 4 2 4 2 2 1 4 0 2 4 2 4 4 2 4 1 4\n",
      " 0 4 4 1 4 0 1 2 4 4 4 4 3 4 4 0 0 4 2 2 0 1 2]\n",
      "testing resnet acc:0.61\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "train_embeddings_res = all_embeddings[0:n_train]\n",
    "testing_embeddings_res = all_embeddings[n_train:n_train+n_test]\n",
    "train_pre_res = torch.nn.functional.softmax(resnet_extractor.fc(train_embeddings_res),dim=1)\n",
    "testing_pre_res = torch.nn.functional.softmax(resnet_extractor.fc(testing_embeddings_res),dim=1)\n",
    "train_pre_res_class = torch.argmax(train_pre_res,dim=1)\n",
    "testing_pre_res_class = torch.argmax(testing_pre_res,dim=1)\n",
    "#testing set\n",
    "acc = sklearn.metrics.accuracy_score(all_classes[n_train:n_train+n_test], testing_pre_res_class.detach().cpu())\n",
    "# auc = sklearn.metrics.roc_auc_score(all_classes[n_train:n_train+n_test],testing_pre_res.detach().cpu(),multi_class=\"ovo\")\n",
    "print(len(all_classes[n_train:n_train+n_test]))\n",
    "print(len(testing_pre_res_class))\n",
    "print(testing_pre_res_class.detach().cpu().numpy())\n",
    "\n",
    "print(\"testing resnet acc:{:.2f}\".format(acc))\n",
    "# print(\"testing resnet auc:{:.2f}\".format(auc))\n",
    "\n",
    "# #training set\n",
    "# acc = sklearn.metrics.accuracy_score(all_classes[0:n_train], train_pre_res_class.detach().cpu())\n",
    "# auc = sklearn.metrics.roc_auc_score(all_classes[0:n_train],train_pre_res.detach().cpu(),multi_class=\"ovo\")\n",
    "# print(\"training resnet acc:{:.2f}\".format(acc))\n",
    "# print(\"training resnet auc:{:.2f}\".format(auc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- testing the resnet backbone -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca8336d-452c-4fbe-b842-a0b52448cb73",
   "metadata": {},
   "source": [
    "# Split train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1c40e165-a0fe-4925-8b54-35914e047662",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = sklearn.model_selection.KFold(5, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ac42be5d-dd5f-4d25-b90d-b4d288ec7679",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_splits = list(kfold.split(np.empty(len(all_classes)), all_classes))\n",
    "n_folds = len(idx_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3b662c7d-74fd-4ac1-bebf-e31e6027a074",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_seed_rounds = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3d6fdba1-a12c-4b4d-a4d4-49983ae1c4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_round_index = pd.RangeIndex(n_seed_rounds, name='seed_i')\n",
    "fold_index = pd.RangeIndex(n_folds, name='fold_i')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c15dd6cd-2e1b-4e4f-b20f-1dec1f8f18eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# latent_dim_index = pd.Index([2,5,10,12,15,20,30,40,50,60,70,80,90,100], name='dim_i')\n",
    "latent_dim_index = pd.Index([2,5,10], name='dim_i')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c23f37-bd74-4e0e-905e-21b47e672287",
   "metadata": {},
   "source": [
    "# Define and train GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "553a50be-262d-4ed2-99c0-aefcd7c19890",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpytorch.models import ApproximateGP\n",
    "from gpytorch.variational import CholeskyVariationalDistribution\n",
    "from gpytorch.variational import VariationalStrategy\n",
    "\n",
    "class GPModel(ApproximateGP):\n",
    "    def __init__(self, inducing_points,num_classes, latent_dim):\n",
    "        variational_distribution = CholeskyVariationalDistribution(inducing_points.size(0))\n",
    "        variational_strategy = VariationalStrategy(self, inducing_points, variational_distribution, learn_inducing_locations=True)\n",
    "        super(GPModel, self).__init__(variational_strategy)\n",
    "        # self.mean_module = gpytorch.means.ConstantMean()\n",
    "        # self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\n",
    "\n",
    "        self.mean_module = gpytorch.means.ConstantMean(batch_shape=torch.Size((num_classes,)))\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(\n",
    "            gpytorch.kernels.RBFKernel(batch_shape=torch.Size((num_classes,))),\n",
    "            batch_shape=torch.Size((num_classes,)),\n",
    "        )\n",
    "        self.scaler = gpytorch.utils.grid.ScaleToBounds(-1,1)\n",
    "        self.fc = torch.nn.Linear(inducing_points.shape[1],latent_dim)\n",
    "        torch.nn.init.xavier_uniform_(self.fc.weight)\n",
    "\n",
    "    def transform(self, x):\n",
    "        x = self.fc(x)\n",
    "        x = self.scaler(x)\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.transform(x)\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_built_gp_num = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Variational GP Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 2) ... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|                                                                                     | 0/1 [00:00<?, ?it/s]E:\\Users\\nora\\anaconda3\\envs\\deep_gp\\lib\\site-packages\\gpytorch\\likelihoods\\gaussian_likelihood.py:300: GPInputWarning: You have passed data through a FixedNoiseGaussianLikelihood that did not match the size of the fixed noise, *and* you did not specify noise. This is treated as a no-op.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "gp_index = pd.MultiIndex.from_product([fold_index, seed_round_index, latent_dim_index])\n",
    "\n",
    "optimization_trace = pd.Series([list() for _ in gp_index], index=gp_index)\n",
    "models = pd.Series(index=gp_index, dtype=object)\n",
    "\n",
    "for gp_i in gp_index:\n",
    "    print(gp_i,'...', end=' ', flush=True)\n",
    "    fold_i, seed_i, dim_i = gp_i\n",
    "    train_idx, test_idx = idx_splits[fold_i]\n",
    "    train_classes = all_classes[train_idx]\n",
    "    train_embeddings = all_embeddings[train_idx]\n",
    "\n",
    "    test_classes = all_classes[test_idx]\n",
    "    test_embeddings = all_embeddings[test_idx]\n",
    "\n",
    "    # initialize likelihood and model\n",
    "    torch.manual_seed(seed_i)\n",
    "\n",
    "    inducing_points = train_embeddings[:samples_built_gp_num, :]\n",
    "    model = GPModel(inducing_points=inducing_points,num_classes=class_num,latent_dim=dim_i)\n",
    "    # likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "    likelihood = gpytorch.likelihoods.DirichletClassificationLikelihood(targets=train_classes)\n",
    "    likelihood = likelihood.to(device)\n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "    likelihood.train()\n",
    "\n",
    "    mll = gpytorch.mlls.VariationalELBO(likelihood, model, num_data=train_classes.size(0))\n",
    "    mll.train()\n",
    "\n",
    "    optimizer = torch.optim.Adam(mll.parameters(), lr=0.01) \n",
    "\n",
    "\n",
    "    # creating dataloader\n",
    "    from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "    train_dataset = TensorDataset(train_embeddings, train_classes)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    test_dataset = TensorDataset(test_embeddings, test_classes)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    num_epochs = 1\n",
    "    epochs_iter = tqdm(range(num_epochs), desc=\"Epoch\")\n",
    "    for epoch in epochs_iter:\n",
    "        minibatch_iter = tqdm(train_loader, desc=\"Minibatch\", leave=False)\n",
    "        for x_batch, y_batch in minibatch_iter:\n",
    "            optimizer.zero_grad()\n",
    "            x_batch = x_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "            output = likelihood(model(x_batch))\n",
    "            loss = -mll(output, y_batch)\n",
    "            loss = loss.sum()\n",
    "            minibatch_iter.set_postfix(loss=loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "    models[gp_i] = model\n",
    "    print('Done', flush=True)\n",
    "    # botorch.optim.fit.fit_gpytorch_mll_scipy(mll, callback=lambda _,i: optimization_trace.append(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DirichletClassificationLikelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "93ec2af0-2efe-46dc-83b6-b13bf0416192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gp_index = pd.MultiIndex.from_product([fold_index, seed_round_index, latent_dim_index])\n",
    "\n",
    "# optimization_trace = pd.Series([list() for _ in gp_index], index=gp_index)\n",
    "# models = pd.Series(index=gp_index, dtype=object)\n",
    "\n",
    "# for gp_i in gp_index:\n",
    "#     print(gp_i,'...', end=' ', flush=True)\n",
    "#     fold_i, seed_i, dim_i = gp_i\n",
    "#     train_idx, test_idx = idx_splits[fold_i]\n",
    "#     train_classes = all_classes[train_idx]\n",
    "#     train_embeddings = all_embeddings[train_idx]\n",
    "\n",
    "#     test_classes = all_classes[test_idx]\n",
    "#     test_embeddings = all_embeddings[test_idx]\n",
    "\n",
    "#     # initialize likelihood and model\n",
    "#     torch.manual_seed(seed_i)\n",
    "\n",
    "#     inducing_points = train_embeddings[:samples_built_gp_num, :]\n",
    "#     model = GPModel(inducing_points=inducing_points,num_classes=class_num,latent_dim=dim_i)\n",
    "#     likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "#     likelihood = likelihood.to(device)\n",
    "#     model = model.to(device)\n",
    "#     model.train()\n",
    "#     likelihood.train()\n",
    "\n",
    "#     mll = gpytorch.mlls.VariationalELBO(likelihood, model, num_data=train_classes.size(0))\n",
    "#     mll.train()\n",
    "\n",
    "#     optimizer = torch.optim.Adam([\n",
    "#     {'params': model.parameters()},\n",
    "#     {'params': likelihood.parameters()},\n",
    "#     ], lr=0.01) \n",
    "\n",
    "\n",
    "#     # creating dataloader\n",
    "#     from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "#     train_dataset = TensorDataset(train_embeddings, train_classes)\n",
    "#     train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "#     test_dataset = TensorDataset(test_embeddings, test_classes)\n",
    "#     test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "#     num_epochs = 1\n",
    "#     epochs_iter = tqdm(range(num_epochs), desc=\"Epoch\")\n",
    "#     for epoch in epochs_iter:\n",
    "#         minibatch_iter = tqdm(train_loader, desc=\"Minibatch\", leave=False)\n",
    "#         for x_batch, y_batch in minibatch_iter:\n",
    "#             optimizer.zero_grad()\n",
    "#             x_batch = x_batch.to(device)\n",
    "#             y_batch = y_batch.to(device)\n",
    "#             output = model(x_batch)\n",
    "\n",
    "#             pred_samples = output.sample(torch.Size((256,))).exp()\n",
    "#             probabilities = (pred_samples / pred_samples.sum(1, keepdim=True)).mean(0).detach().cpu()\n",
    "#             pred_class = torch.argmax(probabilities,dim=0,keepdim=False)\n",
    "\n",
    "#             loss = -mll(pred_class, y_batch)\n",
    "#             minibatch_iter.set_postfix(loss=loss.item())\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "            \n",
    "#     models[gp_i] = model\n",
    "#     print('Done', flush=True)\n",
    "#     # botorch.optim.fit.fit_gpytorch_mll_scipy(mll, callback=lambda _,i: optimization_trace.append(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "de1d8068-7650-443d-b7fe-ba1cce69419b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# f,axs = plt.subplots(n_folds,1,constrained_layout=True,figsize=(10,2*n_folds), sharex=True)\n",
    "# for fold_i,ax in zip(range(n_folds), axs):\n",
    "#     for gp_i in gp_index[gp_index.get_locs(pd.IndexSlice[fold_i,:,:])]:\n",
    "#         ax.plot([r.step for r in optimization_trace[gp_i]], [r.fval for r in optimization_trace[gp_i]])\n",
    "#     ax.set_ylabel('Marginal log-lik');\n",
    "# axs.flat[-1].set_xlabel('Steps');\n",
    "# plt.show(f);plt.close(f)\n",
    "# # print(optimization_trace[-1].status, optimization_trace[-1].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912e6637-4f98-4eab-981a-c439d754acbe",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "10a41479-ece1-4766-a580-3a1314e8824c",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = pd.DataFrame(columns=['acc','auc'],index=gp_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1d11b360-c571-47df-9c68-d2b6a22e2620",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_plots = n_folds\n",
    "n_cols = 5\n",
    "n_rows = int(np.ceil(n_plots / n_cols))\n",
    "# f,axs = plt.subplots(n_rows,n_cols, sharey=True, sharex=True, figsize=(n_cols*4, n_rows*4))\n",
    "for fold_i in fold_index:\n",
    "    train_idx, test_idx = idx_splits[fold_i]\n",
    "    test_classes = all_classes[test_idx]\n",
    "    test_embeddings = all_embeddings[test_idx]\n",
    "    for gp_i in gp_index[gp_index.get_locs(pd.IndexSlice[fold_i,:,:])]:\n",
    "        model = models[gp_i]\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            test_pred_dist = model(test_embeddings)\n",
    "\n",
    "        # test_pred_samples = test_pred_dist.sample(torch.Size((256,))).exp()\n",
    "        # test_probabilities = (test_pred_samples / test_pred_samples.sum(1, keepdim=True)).mean(0).detach().cpu()\n",
    "\n",
    "        test_pred_class = torch.argmax(test_pred_dist.loc,dim=0)\n",
    "        # test_pred_class = torch.argmax(test_probabilities,dim=0,keepdim=False)\n",
    "\n",
    "        acc = sklearn.metrics.accuracy_score(test_classes.cpu(), test_pred_class.cpu())\n",
    "        # auc = sklearn.metrics.roc_auc_score(test_classes,test_probabilities,multi_class=\"ovo\")\n",
    "        metrics.at[gp_i, 'acc'] = acc\n",
    "        # metrics.at[gp_i, 'auc'] = auc\n",
    "\n",
    "        # disp = sklearn.metrics.ConfusionMatrixDisplay(\n",
    "        #     sklearn.metrics.confusion_matrix(test_classes, test_pred_class),\n",
    "        #     display_labels=class_labels\n",
    "        # )\n",
    "        # axs.flat[fold_i].set_title(f'Fold {fold_i+1:02d} (ACC: {acc*100:0.2f} AUC: {auc:0.2f})')\n",
    "        # disp.plot(ax=axs.flat[fold_i], colorbar=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "47669275-6f6d-48b6-a7b2-10336f23fba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.18 ± 0.03</td>\n",
       "      <td>nan ± nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           acc        auc\n",
       "0  0.18 ± 0.03  nan ± nan"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics by latent dimension\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dim_i</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.18 ± 0.03</td>\n",
       "      <td>nan ± nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.18 ± 0.03</td>\n",
       "      <td>nan ± nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.18 ± 0.03</td>\n",
       "      <td>nan ± nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               acc        auc\n",
       "dim_i                        \n",
       "2      0.18 ± 0.03  nan ± nan\n",
       "5      0.18 ± 0.03  nan ± nan\n",
       "10     0.18 ± 0.03  nan ± nan"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Metrics')\n",
    "display(metrics.apply(lambda y: f'{y.mean():0.2f} ± {2*y.std():0.2f}').to_frame().T)\n",
    "print('Metrics by latent dimension')\n",
    "display(metrics.groupby(level=[2]).apply(lambda x: x.apply(lambda y: f'{y.mean():0.2f} ± {2*y.std():0.2f}')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7daaf087-17c7-43f9-9a62-9bb9b54a8765",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DirichletClassificationLikelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c2ceff-571e-4c6d-97fa-3368fef0ab11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862e4e45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0211a81f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_gp",
   "language": "python",
   "name": "deep_gp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
