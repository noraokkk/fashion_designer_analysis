{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd7eb8b5-1e17-4b67-92cb-c4d4bec97dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages for model learning\n",
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import gpytorch\n",
    "import botorch\n",
    "\n",
    "# Packages for data loading\n",
    "import json\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb42c13-8a0a-43d2-be92-1243fa82c2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages for Jupyter notebook\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "import base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99da150",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import cache\n",
    "\n",
    "tensor_to_image = torchvision.transforms.ToPILImage()\n",
    "@cache\n",
    "def tensor_to_url(tensor, size=128):\n",
    "    return fr\"data:image/png;base64,{base64.b64encode(PIL.ImageOps.contain(tensor_to_image(tensor), (size, size))._repr_png_()).decode('ascii')}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33eb9613-1cb7-4a50-be91-96f1c970e580",
   "metadata": {},
   "source": [
    "# Load and process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb725f3-a290-4201-9064-ebc7ada35dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "\n",
    "# img_root = './dataset/dress_pure_renamed/'\n",
    "# train_metadata = json.loads(Path('./dataset/dress_pure_renamed/train.json').read_text())\n",
    "# test_metadata = json.loads(Path('./dataset/dress_pure_renamed/test.json').read_text())\n",
    "# val_metadata = json.loads(Path('./dataset/dress_pure_renamed/val.json').read_text())\n",
    "\n",
    "# class_labels = ['christian_dior', 'maison_margiela']\n",
    "torch.manual_seed(0)\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = \"cpu\"\n",
    "\n",
    "img_root = '/home/sicelukwanda/modm/datasets/fashion_designers_list/'\n",
    "train_metadata = json.loads(Path('/home/sicelukwanda/modm/datasets/fashion_designers_list/train.json').read_text())\n",
    "test_metadata = json.loads(Path('/home/sicelukwanda/modm/datasets/fashion_designers_list/test.json').read_text())\n",
    "val_metadata = json.loads(Path('/home/sicelukwanda/modm/datasets/fashion_designers_list/val.json').read_text())\n",
    "\n",
    "class_labels = [\"alexander_mcqueen\",\"donatella_versace\",\"john_galliano\",\"karl_lagerfeld\",\"yves_saint_laurent\"]\n",
    "print(class_labels)\n",
    "\n",
    "n_train = len(train_metadata)\n",
    "n_test = len(test_metadata)\n",
    "n_val = len(val_metadata)\n",
    "\n",
    "train_classes = torch.empty(n_train, dtype=torch.int)\n",
    "train_images = [None]*n_train\n",
    "for i,meta in enumerate(train_metadata):\n",
    "    train_classes[i] = meta['label']\n",
    "    train_images[i] = torchvision.io.read_image(img_root+meta['file_path']).to(device)\n",
    "\n",
    "test_classes = torch.empty(n_test, dtype=torch.int)\n",
    "test_images = [None]*n_test\n",
    "for i,meta in enumerate(test_metadata):\n",
    "    test_classes[i] = meta['label']\n",
    "    test_images[i] = torchvision.io.read_image(img_root+meta['file_path']).to(device)\n",
    "\n",
    "val_classes = torch.empty(n_test, dtype=torch.int)\n",
    "val_images = [None]*n_val\n",
    "for i,meta in enumerate(val_metadata):\n",
    "    test_classes[i] = meta['label']\n",
    "    val_images[i] = torchvision.io.read_image(img_root+meta['file_path']).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db7c63e-3a89-4a7b-83ab-3dc48a3dbc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make all photos square\n",
    "def pad_image(img):\n",
    "    h,w = img.shape[1:]\n",
    "    if h != w:\n",
    "        new_w = max(h,w)\n",
    "        pad_h, rem_h = divmod(new_w - h, 2)\n",
    "        pad_w, rem_w = divmod(new_w - w, 2)\n",
    "        padding = [pad_w, pad_h, pad_w+rem_w, pad_h+rem_h]\n",
    "        return torchvision.transforms.functional.pad(img, padding, padding_mode='edge')\n",
    "    return img\n",
    "\n",
    "train_images = [pad_image(i) for i in train_images]\n",
    "test_images = [pad_image(i) for i in test_images]\n",
    "val_images = [pad_image(i) for i in val_images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d56903",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_images))\n",
    "print(len(test_images))\n",
    "print(len(val_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9af8a3-cdb0-4b18-90ad-c25f376380b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResnetExtractor(torch.nn.Module):\n",
    "    def __init__(self, remove_last_layer=True):\n",
    "        super().__init__()\n",
    "        weights = torchvision.models.ResNet18_Weights.DEFAULT\n",
    "        self.resnet18 = torchvision.models.resnet18(weights=weights, progress=False).eval()\n",
    "#         self.input_transform = weights.transforms(antialias=True)\n",
    "        \n",
    "        self.input_transform = weights.transforms()\n",
    "\n",
    "        # Remove resnet last layer\n",
    "        if remove_last_layer:\n",
    "            self.resnet18.fc = torch.nn.Identity()\n",
    "\n",
    "        # Freeze all the parameters\n",
    "        for param in self.resnet18.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        with torch.no_grad():\n",
    "            y_pred = self.resnet18(x)\n",
    "            return y_pred\n",
    "\n",
    "# Define resnet feature extractor\n",
    "resnet_extractor = ResnetExtractor(remove_last_layer=True).to(device)\n",
    "crop_size = resnet_extractor.input_transform.crop_size[0]\n",
    "\n",
    "train_data = torch.empty((n_train, 3, crop_size, crop_size)).to(device)\n",
    "test_data = torch.empty((n_test, 3, crop_size, crop_size)).to(device)\n",
    "val_data = torch.empty((n_val, 3, crop_size, crop_size)).to(device)\n",
    "for i in range(n_train):\n",
    "    train_data[i] = resnet_extractor.input_transform(train_images[i])\n",
    "for i in range(n_test):\n",
    "    test_data[i] = resnet_extractor.input_transform(test_images[i])\n",
    "for i in range(n_val):\n",
    "    val_data[i] = resnet_extractor.input_transform(val_images[i])\n",
    "\n",
    "train_embeddings = resnet_extractor(train_data)\n",
    "test_embeddings = resnet_extractor(test_data)\n",
    "val_embeddings = resnet_extractor(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7baa0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#res18 backbone\n",
    "# Define resnet feature extractor\n",
    "import torch, torch.nn as nn, torch.nn.functional as F\n",
    "epoches = 10\n",
    "resnet_backbone = ResnetExtractor(remove_last_layer=False).to(device)\n",
    "fc = torch.nn.Linear(1000,len(class_labels)).train()\n",
    "fc = fc.to(device)\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, fc.parameters()),lr=0.001)#, weight_decay=0.0004)\n",
    "\n",
    "loss_record = []\n",
    "for i in range(0,epoches):\n",
    "    train_embeddings_res = resnet_backbone(train_data)\n",
    "    output_res = fc(train_embeddings_res)\n",
    "    output_res = F.log_softmax(output_res, dim=1)\n",
    "    loss = F.nll_loss(output_res,train_classes.long())\n",
    "    print('training loss: {:.2f}:'.format(loss.data))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    loss_record.append(loss.data)\n",
    "\n",
    "f,ax = plt.subplots(1,1,tight_layout=True,figsize=(10,3))\n",
    "ax.plot([i for i in range(0,epoches)], loss_record)\n",
    "ax.set_ylabel('training loss');ax.set_xlabel('epoch');\n",
    "plt.show(f);plt.close(f)\n",
    "\n",
    "\n",
    "##testing\n",
    "test_embeddings_res = resnet_backbone(test_data)\n",
    "output_res = fc(test_embeddings_res)\n",
    "# pred = output_res.argmax(-1)\n",
    "output_res = torch.softmax(output_res,dim=1).detach().cpu()\n",
    "\n",
    "print('ROC-AUC',np.round(sklearn.metrics.roc_auc_score(\n",
    "    test_classes,\n",
    "    output_res,multi_class='ovr'\n",
    "),2))\n",
    "\n",
    "print('Acc',np.round(sklearn.metrics.accuracy_score(\n",
    "    test_classes,\n",
    "    output_res.argmax(-1)\n",
    ")*100,2),'%')\n",
    "\n",
    "# print(test_classes)\n",
    "# print(output_res.argmax(-1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c23f37-bd74-4e0e-905e-21b47e672287",
   "metadata": {},
   "source": [
    "# Define and train GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553a50be-262d-4ed2-99c0-aefcd7c19890",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DirichletGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood, num_classes):\n",
    "        super(DirichletGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean(batch_shape=torch.Size((num_classes,)))\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(\n",
    "            gpytorch.kernels.RBFKernel(batch_shape=torch.Size((num_classes,))),\n",
    "            batch_shape=torch.Size((num_classes,)),\n",
    "        )\n",
    "        self.scaler = gpytorch.utils.grid.ScaleToBounds(-1,1)\n",
    "        self.fc = torch.nn.Linear(train_x.shape[1],10)\n",
    "        torch.nn.init.xavier_uniform_(self.fc.weight)\n",
    "\n",
    "    def transform(self, x):\n",
    "        x = self.fc(x)\n",
    "        x = self.scaler(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.transform(x)\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "    def embedding_posterior(self, z):\n",
    "        '''Compute the posterior over z = self.transform(x)'''\n",
    "        assert self.prediction_strategy is not None\n",
    "        fz_mean = self.mean_module(z)\n",
    "        Kz = self.covar_module(z)\n",
    "        Kzx = self.covar_module(z, self.transform(self.train_inputs[0]))\n",
    "        return gpytorch.distributions.MultivariateNormal(\n",
    "            self.prediction_strategy.exact_predictive_mean(fz_mean,Kzx),\n",
    "            self.prediction_strategy.exact_predictive_covar(Kz, Kzx)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8650b9-b1e0-4f64-b0b2-d744b5460b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize likelihood and model\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# print(train_classes.long())\n",
    "# likelihood = gpytorch.likelihoods.DirichletClassificationLikelihood(train_classes.long(), learn_additional_noise=True)\n",
    "# model = DirichletGPModel(train_embeddings, likelihood.transformed_targets, likelihood, num_classes=likelihood.num_classes)\n",
    "# # print(likelihood.num_classes)\n",
    "\n",
    "likelihood = gpytorch.likelihoods.DirichletClassificationLikelihood(train_classes.long(), learn_additional_noise=True)\n",
    "model = DirichletGPModel(train_embeddings, likelihood.transformed_targets, likelihood, num_classes=likelihood.num_classes)\n",
    "# print(likelihood.num_classes)\n",
    "\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "mll.train()\n",
    "\n",
    "optimization_trace = []\n",
    "botorch.optim.fit.fit_gpytorch_mll_torch(mll, step_limit=1000, optimizer=lambda p: torch.optim.Adam(p, lr=0.01), callback=lambda _,i: optimization_trace.append(i))\n",
    "# botorch.optim.fit.fit_gpytorch_mll_scipy(mll, callback=lambda _,i: optimization_trace.append(i))\n",
    "\n",
    "f,ax = plt.subplots(1,1,tight_layout=True,figsize=(10,3))\n",
    "ax.plot([r.runtime for r in optimization_trace], [r.fval for r in optimization_trace])\n",
    "ax.set_ylabel('Marginal log-lik');ax.set_xlabel('Seconds');\n",
    "plt.show(f);plt.close(f)\n",
    "print(optimization_trace[-1].status, optimization_trace[-1].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912e6637-4f98-4eab-981a-c439d754acbe",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d11b360-c571-47df-9c68-d2b6a22e2620",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "likelihood.eval()\n",
    "with torch.no_grad():\n",
    "    test_pred_dist = model(test_embeddings)\n",
    "\n",
    "test_pred_samples = test_pred_dist.sample(torch.Size((256,))).exp()\n",
    "test_probabilities = (test_pred_samples / test_pred_samples.sum(1, keepdim=True)).mean(0)\n",
    "\n",
    "# print(class_labels)\n",
    "\n",
    "# sklearn.metrics.ConfusionMatrixDisplay(\n",
    "#     sklearn.metrics.confusion_matrix(test_classes, (test_probabilities[1] > 0.5)),\n",
    "#     display_labels=class_labels\n",
    "# ).plot();\n",
    "\n",
    "sklearn.metrics.ConfusionMatrixDisplay(\n",
    "    sklearn.metrics.confusion_matrix(test_classes, (torch.argmax(test_probabilities,dim=0,keepdim=False))),\n",
    "    display_labels=class_labels\n",
    ").plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd044f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "likelihood.eval()\n",
    "with torch.no_grad():\n",
    "    train_pred_dist = model(train_embeddings)\n",
    "\n",
    "train_pred_samples = train_pred_dist.sample(torch.Size((256,))).exp()\n",
    "train_probabilities = (train_pred_samples / train_pred_samples.sum(1, keepdim=True)).mean(0)\n",
    "\n",
    "# print(class_labels)\n",
    "\n",
    "# sklearn.metrics.ConfusionMatrixDisplay(\n",
    "#     sklearn.metrics.confusion_matrix(test_classes, (test_probabilities[1] > 0.5)),\n",
    "#     display_labels=class_labels\n",
    "# ).plot();\n",
    "\n",
    "sklearn.metrics.ConfusionMatrixDisplay(\n",
    "    sklearn.metrics.confusion_matrix(train_classes, (torch.argmax(train_probabilities,dim=0,keepdim=False))),\n",
    "    display_labels=class_labels\n",
    ").plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c4cfab-186f-455b-aba0-1087a4887f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('ROC-AUC',np.round(sklearn.metrics.roc_auc_score(\n",
    "#     test_classes,\n",
    "#     (test_probabilities[1] > 0.5),\n",
    "# ),2))\n",
    "# print('Acc',np.round(sklearn.metrics.accuracy_score(\n",
    "#     test_classes,\n",
    "#     (test_probabilities[1] > 0.5)\n",
    "# )*100,2),'%')\n",
    "\n",
    "# torch.max(test_probabilities,0)[0].shape\n",
    "# test_classes.shape\n",
    "# print(test_probabilities[:,1])\n",
    "\n",
    "torch.softmax(test_probabilities,dim=0).t()\n",
    "\n",
    "print('ROC-AUC',np.round(sklearn.metrics.roc_auc_score(\n",
    "    test_classes,\n",
    "    torch.softmax(test_probabilities,dim=0).t(),multi_class='ovr'\n",
    "),2))\n",
    "\n",
    "print('Acc',np.round(sklearn.metrics.accuracy_score(\n",
    "    test_classes,\n",
    "    (torch.argmax(test_probabilities,dim=0,keepdim=False))\n",
    ")*100,2),'%')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f79bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# def roc_auc_score_multiclass(actual_class, pred_class, average = \"macro\"):\n",
    "\n",
    "#   #creating a set of all the unique classes using the actual class list\n",
    "#   unique_class = set(actual_class)\n",
    "#   roc_auc_dict = {}\n",
    "#   for per_class in unique_class:\n",
    "#     #creating a list of all the classes except the current class \n",
    "#     other_class = [x for x in unique_class if x != per_class]\n",
    "\n",
    "#     #marking the current class as 1 and all other classes as 0\n",
    "#     new_actual_class = [0 if x in other_class else 1 for x in actual_class]\n",
    "#     new_pred_class = [0 if x in other_class else 1 for x in pred_class]\n",
    "\n",
    "#     #using the sklearn metrics method to calculate the roc_auc_score\n",
    "#     roc_auc = roc_auc_score(new_actual_class, new_pred_class, average = average)\n",
    "#     roc_auc_dict[per_class] = roc_auc\n",
    "\n",
    "#   return roc_auc_dict\n",
    "\n",
    "# print(\"\\nLogistic Regression\")\n",
    "# # assuming your already have a list of actual_class and predicted_class from the logistic regression classifier\n",
    "# lr_roc_auc_multiclass = roc_auc_score_multiclass(test_classes, test_probabilities[1] > 0.5)\n",
    "# print(lr_roc_auc_multiclass)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c040a42-1553-499d-88a5-0fc9a1704b93",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83187564-18aa-4f97-b37c-b1c2b2955d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_grid = torch.as_tensor(np.stack(np.meshgrid(np.linspace(-1,1), np.linspace(-1,1)), -1)).to(model.train_inputs[0])\n",
    "y_grid = model.embedding_posterior(x_grid.view(-1,2))\n",
    "\n",
    "y_grid = y_grid.sample(torch.Size((256,))).exp()\n",
    "y_grid_mean = (y_grid / y_grid.sum(1, keepdim=True)).mean(0)\n",
    "\n",
    "all_classes = sorted(train_classes.unique().numpy())\n",
    "n_cols = 4\n",
    "n_rows = int(np.ceil(len(all_classes)/n_cols))\n",
    "f,axs = plt.subplots(\n",
    "    n_rows,n_cols, figsize=(n_cols*3, n_rows*3),\n",
    "    sharex=True, sharey=True, constrained_layout=True\n",
    ")\n",
    "for ax in axs.flat:\n",
    "    ax.set_visible(False)\n",
    "for i in range(len(all_classes)):\n",
    "    ax = axs.flat[i]\n",
    "    ax.set_visible(True)\n",
    "    ax.set_title(f'{class_labels[i]} ({i})', fontsize=8)\n",
    "    ax.imshow(\n",
    "        y_grid_mean[i].view(x_grid.shape[:2]).numpy(force=True), cmap='PiYG',\n",
    "        origin='lower', aspect='auto', extent=[-1,1,-1,1],\n",
    "        vmin=0, vmax=1\n",
    "    )\n",
    "    ax.scatter(\n",
    "        *model.transform((train_embeddings)).numpy(force=True).T,\n",
    "        c=(train_classes != i),\n",
    "        vmin=0, vmax=10, marker='o', cmap='tab10', edgecolor='k',\n",
    "        s=20\n",
    "    )\n",
    "#     ax.scatter(\n",
    "#         *model.transform((test_embeddings)).numpy(force=True).T,\n",
    "#         c=(test_classes != i),\n",
    "#         vmin=0, vmax=10, marker='X', cmap='tab10', edgecolor='k',\n",
    "#         s=40\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e695abfc-22fb-4743-a8ba-75e0b75f16aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    kernel_test_train = model.covar_module(model.transform(test_embeddings), model.transform(train_embeddings)).evaluate().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08030659-1d6c-4a14-9660-a9206253afd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "<style>\n",
    "    html {\n",
    "        --small-size: 42px;\n",
    "    }\n",
    "    .small-box {\n",
    "        width: calc(var(--small-size) - 4px); height: calc(var(--small-size) - 2px);\n",
    "        border-top: 2px solid; border-left: 2px solid;\n",
    "        //flex: 0 0 auto;\n",
    "    }\n",
    "    .small-holder {\n",
    "        display: flex;\n",
    "        flex-direction: column;\n",
    "        flex-wrap: wrap;\n",
    "        border: 2px solid;\n",
    "        box-sizing: border-box;\n",
    "        border-top: 0;\n",
    "        border-left: 0;\n",
    "        height: calc(var(--small-size) * 4);\n",
    "        width: calc(var(--small-size)*2);\n",
    "    }\n",
    "    .small-holder > .small-box:nth-child(4n) {\n",
    "        height: calc(var(--small-size) - 4px);\n",
    "    }\n",
    "    .big-box {\n",
    "        width: calc(var(--small-size) * 4); height: calc(var(--small-size) * 4);\n",
    "    }\n",
    "    .img-box > img {\n",
    "        //border-left: 1px dashed red;\n",
    "        //border-right: 1px dashed red;\n",
    "    }\n",
    "    .border {\n",
    "        border: 2px solid;\n",
    "        box-sizing: border-box;\n",
    "    }\n",
    "    .img-box {}\n",
    "    .img-box > img {\n",
    "        display: block;\n",
    "        margin: 0 auto;\n",
    "        max-height: 100%;\n",
    "        max-width: 100%;\n",
    "    }\n",
    "    *[data-class=\"0\"] {\n",
    "        border-left: 3px solid #1f77b4;\n",
    "    }\n",
    "    *[data-class=\"1\"] {\n",
    "        border-left: 3px solid #ff7f0e;\n",
    "    }\n",
    "    *[data-class=\"2\"] {\n",
    "        border-left: 3px solid #2ca02c;\n",
    "    }\n",
    "    *[data-class=\"3\"] {\n",
    "        border-left: 3px solid #d62728;\n",
    "    }\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a227ba06-817d-4f9c-a748-c968078b6699",
   "metadata": {},
   "outputs": [],
   "source": [
    "html_str = \"<div style='display: flex;gap: 22px;flex-wrap: wrap;'>\"\n",
    "for i in sorted(range(n_test), key=lambda i: test_probabilities[test_classes[i],i])[:30]:\n",
    "    top_5 = np.argsort(kernel_test_train[0][i])[::-1][:8]\n",
    "    top_5_figures = ''.join([\n",
    "        fr\"\"\"<div class=\"img-box small-box\" data-class=\"{train_classes[j]}\"><img src=\"{tensor_to_url(train_images[j], 42)}\"></div>\"\"\"\n",
    "        for j in top_5\n",
    "    ])\n",
    "    html_str += fr'''<div>\n",
    "    <div style='margin: 0 auto; display: flex;'>\n",
    "    <div class=\"img-box big-box border\" style='border-right: 0 !important;' data-class=\"{test_classes[i]}\">\n",
    "        <img src=\"{tensor_to_url(test_images[i], 192)}\">\n",
    "    </div>\n",
    "    <div class=\"small-holder\">{top_5_figures}</div>\n",
    "    </div>\n",
    "    <pre>\n",
    "P(c={test_classes[i]}): {100*test_probabilities[test_classes[i],i].numpy(force=True):0.2f}%\n",
    "Class:  {class_labels[test_classes[i]]}</pre> \n",
    "    </div>'''\n",
    "html_str += '</div>'\n",
    "ipd.HTML(html_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce54226d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:sd_automatic111] *",
   "language": "python",
   "name": "conda-env-sd_automatic111-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
